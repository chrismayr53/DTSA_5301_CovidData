---
title: "Final project"
author: "Jen Lewis"
date: "2024-06-02"
output: html_document
---

# A visualization of COVID19 cases and deaths

The main purpose of this analysis is to see if there is some correlation between the number of cases to the number of deaths. For this specific analysis we’ll be looking at data from the United States and from the state of Colorado. In lieu of being able to attach a bibliography file I’ll add the citation directly. On their [github page README](https://github.com/CSSEGISandData/COVID-19/blob/master/README.md) they say to cite their article if using the data which is as follows:

Source:

>Dong, E., Du, H., & Gardner, L. (2020). An interactive web-based dashboard to track COVID-19 in real time. 
  >*Lancet. Infectious Diseases/the Lancet. Infectious Diseases, 20(5),* 533–534. https://doi.org/10.1016/s1473-3099(20)30120-1
  
As a final note, the code chunks will be included since this is more of an introduction to r markdown sort of analysis.

# Importing the Data

The first step is to import the data and pull in any packages that will be needed for the project. Once that is complete, we’ll need to create different variables for each of the data sets. The four different data sets are as follows:

1. US cases
2. US deaths
3. Global cases
4. Global deaths


```{r setup, include = TRUE, warning = FALSE}

knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)

# Get the current data for the four files
url_in <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/"
file_names <- c("time_series_covid19_confirmed_US.csv","time_series_covid19_confirmed_global.csv", "time_series_covid19_deaths_US.csv", "time_series_covid19_deaths_global.csv")
urls <- str_c(url_in, file_names)

# following url is for population look ups
uid_lookup_url <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv"

# adding url for country information for an extra analysis of the global data
url_isocountry <- "https://raw.githubusercontent.com/m-muecke/isocountry/main/data-raw/isocountry.csv"

```

```{r import_data, show_col_types = FALSE}

global_cases <- read_csv(urls[2], show_col_types = FALSE)
global_deaths <- read_csv(urls[4], show_col_types = FALSE)
us_cases <- read_csv(urls[1], show_col_types = FALSE)
us_deaths <- read_csv(urls[3], show_col_types = FALSE)
uid <- read_csv(uid_lookup_url, show_col_types = FALSE) %>%
  select(-c(Lat, Long_, Combined_Key, code3, iso3, Admin2))
isocountry <- read_csv(url_isocountry)

```

# Cleaning/Tidying the Data

Next, the data needs to be cleaned a little since it contains a lot of information that isn’t necessarily useful for our analysis such as the Lat, Long, and UID. Another observation with these data sets is that they have a column for every date, which creates a very wide table. For our purposes it would be nice if there were a date column to list out the total cases and deaths for each date. 

``` {r tidying_data, include = TRUE}

# tidy up global cases (and rename so that it's consistent)
global_cases <- global_cases %>% 
  pivot_longer(cols = -c(`Province/State`, `Country/Region`, Lat, Long), 
               names_to = "date", 
               values_to = "cases") %>%
  select(-c(Lat, Long)) %>%
  rename(Country_Region = `Country/Region`, Province_State = `Province/State`)

# tidy up global deaths
global_deaths <- global_deaths %>% 
  pivot_longer(cols = -c(`Province/State`, `Country/Region`, Lat, Long), 
               names_to = "date", 
               values_to = "deaths") %>%
  select(-c(Lat, Long)) %>%
  rename(Country_Region = `Country/Region`, Province_State = `Province/State`)

# tidy up US cases
us_cases <- us_cases %>%
  pivot_longer(cols = -(UID:Combined_Key),
               names_to = "date",
               values_to = "cases") %>%
  select(Admin2:cases) %>%
  select(-c(Lat, Long_))

# tidy up US Deaths
us_deaths <- us_deaths %>%
  pivot_longer(cols = -(UID:Population),
               names_to = "date",
               values_to = "deaths") %>%
  select(Admin2:deaths) %>%
  select(-c(Lat, Long_))

```

For a finer grain cleaning I chose to filter out where cases and deaths came out as NA. In this step we’ll also transform the date into a date object using lubridate.

The final transformation we'll make before considering what to plot, is to create new data sets with the combined cases and deaths for each region. Additionally we'll add on the population to the global data set since that information is available from John Hopkins University in the same location that we got the COVID19 data from.

``` {r transforming_data, include = TRUE}

# get cases and deaths that are greater than 0
global_cases <- global_cases %>% 
  mutate(date = mdy(date)) %>%
  filter(!is.na(cases)) 

global_deaths <- global_deaths %>% 
  mutate(date = mdy(date)) %>%
  filter(!is.na(deaths)) 

us_cases <- us_cases %>% 
  mutate(date = mdy(date)) %>%
  filter(!is.na(cases)) 

us_deaths <- us_deaths %>% 
  mutate(date = mdy(date)) %>%
  filter(!is.na(deaths)) 

# join deaths and cases data sets together
global <- global_cases %>% 
  full_join(global_deaths)

US <- us_cases %>%
  full_join(us_deaths)

# add the combined key to global
global <- global %>%
  unite("Combined_Key",
        c(Province_State, Country_Region),
        sep = ", ",
        na.rm = TRUE,
        remove = FALSE)

# add population to global
global <- global %>%
  left_join(uid, by = c("Province_State", "Country_Region")) %>%
  select(-c(UID, FIPS)) %>%
  filter(!is.na(Population))

summary(global)
summary(US)

```

# Initial Plotting of US Data

Now that the data has been cleaned and organized in a useful way, we’ll continue with considering how to plot the data. At this point we will only be considering the US data set. Since this analysis is a comparison of cases to deaths it would be useful to group the data by state. We’ll also examine the ratio of deaths per million by the population for the state to see how the data is looking at this point to see if we’ve gone wrong somewhere.

``` {r setup_us_data_for_plot, include = TRUE}

# get the cases and deaths by state
US_by_state <- US %>%
  group_by(Province_State, Country_Region, date) %>%
  summarize(cases = sum(cases), deaths = sum(deaths), Population = sum(Population)) %>%
  mutate(deaths_per_mill = deaths * 1000000 / Population) %>% 
  select(Province_State, Country_Region, date, cases, deaths, deaths_per_mill, Population) %>%
  ungroup()

# get totals for the us per date
US_totals <- US_by_state %>%
  group_by(Country_Region, date) %>%
  summarize(cases = sum(cases), deaths = sum(deaths), Population = sum(Population)) %>%
  mutate(deaths_per_mill = deaths * 1000000 / Population) %>%
  select(Country_Region, date, cases, deaths, deaths_per_mill, Population) %>%
  ungroup()

tail(US_totals)

```

The ratio of deaths per million looks believable so we’ll continue with plotting. To plot we’ll make the x-axis the date and create dots connected by lines that represent the totals for each data for deaths and cases on the y-axis. The y-axis will also be scaled by log base 10.

``` {r plotting_us_data, include = TRUE}

US_totals %>%
  filter(cases > 0) %>%
  ggplot(aes(x = date, y = cases)) +
  geom_line(aes(color = "cases")) +
  geom_point(aes(color = "cases")) + 
  geom_line(aes(y = deaths, color = "deaths")) +
  geom_point(aes(y = deaths, color = "deaths")) + 
  scale_y_log10() + 
  theme(legend.position = "bottom", axis.text.x = element_text(angle = 90)) +
  labs(title = "COVID19 in US", y = NULL)

```

``` {r plotting_colorado_data, include = TRUE,  warning = FALSE}

state <- "Colorado"
US_by_state %>%
  filter(Province_State == state) %>%
  filter(cases > 0) %>%
  ggplot(aes(x = date, y = cases)) +
  geom_line(aes(color = "cases")) +
  geom_point(aes(color = "cases")) + 
  geom_line(aes(y = deaths, color = "deaths")) +
  geom_point(aes(y = deaths, color = "deaths")) + 
  scale_y_log10() + 
  theme(legend.position = "bottom", axis.text.x = element_text(angle = 90)) +
  labs(title = "COVID19 in Colorado", y = NULL)

```

So, looking at the plotted data we’re seeing something similar to what Dr. Wall was seeing where there’s a sharp uptick and the data appears to level off. The data from Colorado appears to have slight upticks in the data so we’ll need to do some more analysis to see what’s potentially happening.

# Analyzing our Initial Findings and Replotting

Before we replot our data we’ll create new columns for the new cases and new deaths in each state and in the US totals. Considering new cases and deaths that occurred on the date will give us more insight into the actual spread and mortality of COVID19, although this is still not a perfect way to analyze the data since we don’t know the specifics of how this data was recorded or potentially how long people took to report illness and death.

After we transform the data again we'll replot using the same plots except with the new cases and new death totals.


``` {r analyzing_data, include = TRUE}

# remove the lag so that we're only visualizing the newer cases and deaths
US_by_state <- US_by_state %>%
  mutate(new_cases = cases - lag(cases), new_deaths = deaths - lag(deaths))

US_totals <- US_totals %>%
  mutate(new_cases = cases - lag(cases), new_deaths = deaths - lag(deaths))

tail(US_totals %>% select(new_cases, new_deaths, everything()))

```

``` {r replotting_us_data, include = TRUE,  warning = FALSE}

US_totals %>%
  ggplot(aes(x = date, y = new_cases)) +
  geom_line(aes(color = "new_cases")) +
  geom_point(aes(color = "new_cases")) + 
  geom_line(aes(y = new_deaths, color = "new_deaths")) +
  geom_point(aes(y = new_deaths, color = "new_deaths")) + 
  scale_y_log10() + 
  theme(legend.position = "bottom", axis.text.x = element_text(angle = 90)) +
  labs(title = "COVID19 in US", y = NULL)

```

``` {r replotting_colorado_data, include = TRUE,  warning = FALSE}
US_by_state %>%
  filter(Province_State == state) %>%
  ggplot(aes(x = date, y = new_cases)) +
  geom_line(aes(color = "new_cases")) +
  geom_point(aes(color = "new_cases")) + 
  geom_line(aes(y = new_deaths, color = "new_deaths")) +
  geom_point(aes(y = new_deaths, color = "new_deaths")) + 
  scale_y_log10() + 
  theme(legend.position = "bottom", axis.text.x = element_text(angle = 90)) +
  labs(title = "COVID19 in Colorado", y = NULL)

```

Lastly, we'll look at the state totals for cases and deaths. We'll extract the 10 states that were the most affected by COVID19 and the 10 states that were the least affected, meaning we're looking at maximum and minimum death counts per thousand. This data is important to look at and play around with because it can potentially lead us to more questions about why certain states were more affected than others.

``` {r analyzing_totals_by_state, include = TRUE}

# analyze state totals and look at max and min by state
US_state_totals <- US_by_state %>%
  group_by(Province_State) %>%
  summarize(deaths = max(deaths), cases = max(cases), Population = max(Population), 
            cases_per_thou = 1000 * cases / Population, 
            deaths_per_thou = 1000 * deaths / Population) %>%
  filter(cases > 0) %>%
  filter(!is.infinite(cases_per_thou))

US_state_totals %>%
  slice_min(deaths_per_thou, n = 10) %>%
  select(deaths_per_thou, cases_per_thou, everything())

US_state_totals %>%
  slice_max(deaths_per_thou, n = 10) %>%
  select(deaths_per_thou, cases_per_thou, everything())

```

We can see that the top ten has drastically changed since Dr. Wall initially recorded her videos. There used to be a lot of states in the New England region, but now we can see that there are a lot of Southern states that have been more affected by COVID19 deaths than any Eastern state.

# Create a Model and Analyze Predictions

Lastly, for this analysis we'll create a simple linear model to see if the cases is a predictor of the amount of deaths that will happen on a given day. We'll do this by creating a new data set with the prediction from the linear modal and then plotting the actual cases and deaths compared to the prediction.

``` {r modeling_us_data, include = TRUE}

mod <- lm(deaths_per_thou ~ cases_per_thou, data = US_state_totals)

summary(mod)

# adding the prediction variable into a new data set
US_totals_w_pred <- US_state_totals %>% mutate(pred = predict(mod))

```

``` {r plot_model_w_prediction, include = TRUE}

US_totals_w_pred %>% ggplot() +
  geom_point(aes(x = cases_per_thou, y = deaths_per_thou), color = "blue") +
  geom_point(aes(x = cases_per_thou, y = pred), color = "red") +
  labs(title = "Prediction Model COVID19", x = "cases per thousand", y = "deaths per thousand")

```


# Analysis of Global Data

Lastly we'll do an analysis of the spread and impact of COVID19 in the globe from 2020 to 2023. To do this we'll need to get the continent information for each country to make the plots a little easier to interpret. To do this we'll be using the raw data from the following [isocountry github project](https://github.com/m-muecke/isocountry/tree/main), which contains countries with more detailed information and the iso codes. Utilizing the iso code we can join the isocountry data into our global data and know the continent of each.

``` {r clean_iso_data, include = TRUE}

# for the isocountry information all we really want is continent, and country values 
# since that will allow us to add the continent to our global data

isocountry <- isocountry %>%
  mutate(iso2 = alpha_2) %>%
  select(c(iso2, region_name, subregion_name))

# add in the continent/region for each country as well
global <- global %>% 
  left_join(isocountry, by = (c("iso2"))) %>%
  select(Province_State, Country_Region, subregion_name, region_name, date,
         cases, deaths, Population,
         Combined_Key)

summary(global)

```

Next we'll need to get the new cases and new deaths similarly to what we did with the US data. This will give us more meaningful data of how COVID19 affected different areas of the world. We'll also extract the year from each date and sum the deaths and cases for that year.

``` {r new_cases_deaths_global, include = TRUE}

# get the new data for cases and deaths, similarly to before
global_new <- global %>%
  mutate(new_cases = cases - lag(cases),
         new_deaths = deaths - lag(deaths)) %>%
  filter(new_cases > 0)

global_new_totals_by_year <- global_new %>%
  mutate(year = year(date)) %>%
  select(-c(date)) %>%
  group_by(year, Province_State, Country_Region, subregion_name, region_name) %>%
  summarize(new_cases = sum(new_cases), new_deaths = sum(new_deaths), Population = sum(Population), 
            cases_per_thou = 1000 * new_cases / Population,
            deaths_per_thou = 1000 * new_deaths / Population) %>% 
  select(year, Province_State, Country_Region, subregion_name, region_name, new_cases, new_deaths, Population, cases_per_thou, deaths_per_thou) %>%
  ungroup()

```


Now we'll plot our cleaned data with each continent in it's own separate plot. Each plot will be broken down into years and we'll look at the totals from the perspective of subregions to get a better idea of what could potentially be happening with the data.

I also should note that countries that did not have population data were removed from the global data, so there's not plot of Antarctica.


``` {r plot_continent, include = TRUE, }

# Americas
global_new_totals_by_year %>%
  filter(region_name == 'Americas') %>%
  ggplot(aes(x = deaths_per_thou, y = cases_per_thou, colour = subregion_name)) + 
  geom_point(alpha = 0.5) +
  scale_y_log10() + 
  facet_wrap(~year) + 
  labs(
    title = "COVID19 In North and South America", 
    x = "deaths per thousand", 
    y = "cases per thousand", 
    colour = "Subregion",
    caption = "continent and subregion data from isocountry github project")

# Africa
global_new_totals_by_year %>%
  filter(region_name == 'Africa') %>%
  ggplot(aes(x = deaths_per_thou, y = cases_per_thou, colour = subregion_name)) + 
  geom_point(alpha = 0.5) +
  scale_y_log10() + 
  facet_wrap(~year) + 
  labs(
    title = "COVID19 In Africa", 
    x = "deaths per thousand", 
    y = "cases per thousand", 
    colour = "Subregion",
    caption = "continent and subregion data from isocountry github project")

# Europe
global_new_totals_by_year %>%
  filter(region_name == 'Europe') %>%
  ggplot(aes(x = deaths_per_thou, y = cases_per_thou, colour = subregion_name)) + 
  geom_point(alpha = 0.5) +
  scale_y_log10() + 
  facet_wrap(~year) + 
  labs(
    title = "COVID19 In Europe", 
    x = "deaths per thousand", 
    y = "cases per thousand", 
    colour = "Subregion",
    caption = "continent and subregion data from isocountry github project")


#Asia
global_new_totals_by_year %>%
  filter(region_name == 'Asia') %>%
  ggplot(aes(x = deaths_per_thou, y = cases_per_thou, colour = subregion_name)) + 
  geom_point(alpha = 0.5) +
  scale_y_log10() + 
  facet_wrap(~year) + 
  labs(
    title = "COVID19 In Asia",
    x = "deaths per thousand", 
    y = "cases per thousand", 
    colour = "Subregion",
    caption = "continent and subregion data from isocountry github project")

# Oceania
global_new_totals_by_year %>%
  filter(region_name == 'Oceania') %>%
  ggplot(aes(x = deaths_per_thou, y = cases_per_thou, colour = subregion_name)) + 
  geom_point(alpha = 0.5) +
  scale_y_log10() + 
  facet_wrap(~year) + 
  labs(
    title = "COVID19 In Oceania", 
    x = "deaths per thousand", 
    y = "cases per thousand", 
    colour = "Subregion",
    caption = "continent and subregion data from isocountry github project")


```

Something that's interesting is that we can see in Africa and Asia there are some regions who appear to not be reporting many deaths at all. What this shows is that we don't know how some countries handled their reporting and if the data is an accurate representation. More poverty stricken countries likely did not record all deaths and all cases the way first world countries were and we also don't know politically what was happening in each country at the time. One country with a very low death toll happens to be North Korea, not only that but they had more reported deaths than reported cases.

``` {r north_korea_data, include = TRUE}

global_totals_by_country <- global %>%
   group_by(Province_State, Country_Region, subregion_name, region_name) %>%
   summarize(cases = max(cases), deaths = max(deaths), Population = max(Population)) %>% 
   select(Province_State, Country_Region, subregion_name, region_name, cases, deaths, Population) %>%
   ungroup()

n_korea_total <- global_totals_by_country %>%
  filter(Country_Region == "Korea, North")

n_korea_total
```

# Conclusion and Bias Indentification

Compared to the plot that Dr. Wall created in the video the actual deaths is far more varied than the linear prediction. To understand why the data has varied so much after three years we would need to do a more detail analysis and see what other factors affect the number of deaths. Even knowing if different strains have different death ratios would probably clear up some of this data quite a bit.

As far as global data goes we cannot know for sure how accurate all of the data is, because we simply do not know how each country handled their reporting. There are many factors that could have introduced bias into the data, such as politics, wealth gaps, religious government bodies, ect. John Hopkins University is also a US institution so naturally they probably had easier access to reporting in the US rather than globally.